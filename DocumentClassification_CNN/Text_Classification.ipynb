{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "829caaa27e9c409aad0c75e28206f53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34dee9465d6f4ea78f57fa672b86d24f",
              "IPY_MODEL_e8ae3dde63f74d66ab8f6558d70b14f3",
              "IPY_MODEL_fe9e8d9ce70d45d1b3078995bc1d3f52"
            ],
            "layout": "IPY_MODEL_1a588121bad54354bcea11fd008c75b9"
          }
        },
        "34dee9465d6f4ea78f57fa672b86d24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f933a3b22f9455a8046392d8893330b",
            "placeholder": "​",
            "style": "IPY_MODEL_ec18a3fb1a094f2faaeed274db038fd2",
            "value": "Processing files: 100%"
          }
        },
        "e8ae3dde63f74d66ab8f6558d70b14f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26f6b34dea0c4872b421ab6b21ffd4f7",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f44ff6b99044f6698839e2cc68aba1a",
            "value": 10
          }
        },
        "fe9e8d9ce70d45d1b3078995bc1d3f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf556d0b3c44d58a3fa3b9310abd436",
            "placeholder": "​",
            "style": "IPY_MODEL_937cfc82d8784377b1e1d12a274a128e",
            "value": " 10/10 [00:05&lt;00:00,  2.64it/s]"
          }
        },
        "1a588121bad54354bcea11fd008c75b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f933a3b22f9455a8046392d8893330b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec18a3fb1a094f2faaeed274db038fd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26f6b34dea0c4872b421ab6b21ffd4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f44ff6b99044f6698839e2cc68aba1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cf556d0b3c44d58a3fa3b9310abd436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "937cfc82d8784377b1e1d12a274a128e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3acc1db1c9d46c4b1985c13581fbb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c8d01edbcc64a4f9ff6a69be3e33fb2",
              "IPY_MODEL_f61d16c0b02247838d929d9b2b3f3e91",
              "IPY_MODEL_628ec3989da242d1b675fb5d5eefee17"
            ],
            "layout": "IPY_MODEL_4c6e5c064f154e938420b987513009f5"
          }
        },
        "8c8d01edbcc64a4f9ff6a69be3e33fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8086a626076540a59f09e140fa31227d",
            "placeholder": "​",
            "style": "IPY_MODEL_cae8b9217c0f489ba727d5f6d9fb53ca",
            "value": "100%"
          }
        },
        "f61d16c0b02247838d929d9b2b3f3e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75c22de6e2a84c5a9a8e52f34d445269",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01bafba4addd47e09da2905d932c02ff",
            "value": 10
          }
        },
        "628ec3989da242d1b675fb5d5eefee17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_836ffa74979b4cf2a31834d7b2288795",
            "placeholder": "​",
            "style": "IPY_MODEL_ca564868b3934f8cad8e03cec3409e08",
            "value": " 10/10 [00:01&lt;00:00, 10.06it/s]"
          }
        },
        "4c6e5c064f154e938420b987513009f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8086a626076540a59f09e140fa31227d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae8b9217c0f489ba727d5f6d9fb53ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75c22de6e2a84c5a9a8e52f34d445269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01bafba4addd47e09da2905d932c02ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "836ffa74979b4cf2a31834d7b2288795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca564868b3934f8cad8e03cec3409e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9438c32866d9408ba209b17b0dd7fe92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f8deb7eb76b43edb5d6b63cce7c3fdd",
              "IPY_MODEL_e4209da1c89b441397fda8c9d67b5b9c",
              "IPY_MODEL_7236576b32244aec90b0211cfd3c3ee6"
            ],
            "layout": "IPY_MODEL_97eee71ac1de409593068dc6d4c98d9b"
          }
        },
        "2f8deb7eb76b43edb5d6b63cce7c3fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a89354886b8f41728408bab45cb3a590",
            "placeholder": "​",
            "style": "IPY_MODEL_d0d14754fb574ec0aac723a5386bbe74",
            "value": "Processing lines: 100%"
          }
        },
        "e4209da1c89b441397fda8c9d67b5b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a3b719592f474b86295d4fc18fe2a5",
            "max": 400000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c568656887e4cad88d158d7f76ef0ee",
            "value": 400000
          }
        },
        "7236576b32244aec90b0211cfd3c3ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ffdec3e8f404041824a7146f843807a",
            "placeholder": "​",
            "style": "IPY_MODEL_5bdb7f678d3b4a0cbca82939e4e5f3ca",
            "value": " 400000/400000 [00:06&lt;00:00, 50973.12it/s]"
          }
        },
        "97eee71ac1de409593068dc6d4c98d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89354886b8f41728408bab45cb3a590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0d14754fb574ec0aac723a5386bbe74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80a3b719592f474b86295d4fc18fe2a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c568656887e4cad88d158d7f76ef0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ffdec3e8f404041824a7146f843807a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bdb7f678d3b4a0cbca82939e4e5f3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba0ee13f3e2e48e58ae356e4bb49e78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7124a3d344794c078be13d2b51d12c63",
              "IPY_MODEL_45cfe710b3574cc3b70e4d4943a12c6a",
              "IPY_MODEL_27fd614f0cd04e1380ee45937f41aec4"
            ],
            "layout": "IPY_MODEL_48a6e779051a43e2aef0402ca08c5324"
          }
        },
        "7124a3d344794c078be13d2b51d12c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e0add167af04ec099d530d921a4705b",
            "placeholder": "​",
            "style": "IPY_MODEL_9e4e590039064febb85011f1208e5062",
            "value": "Processing lines: 100%"
          }
        },
        "45cfe710b3574cc3b70e4d4943a12c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f872c56fab94f73a1f3b9bb171e81e0",
            "max": 400000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd3d7486adc54c849da4fdaf68d735e2",
            "value": 400000
          }
        },
        "27fd614f0cd04e1380ee45937f41aec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7081df0ea46c4be4bc38a1b832289c1c",
            "placeholder": "​",
            "style": "IPY_MODEL_80c9dd012dde4a138fb8a5c716d7feef",
            "value": " 400000/400000 [00:27&lt;00:00, 21841.09it/s]"
          }
        },
        "48a6e779051a43e2aef0402ca08c5324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e0add167af04ec099d530d921a4705b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4e590039064febb85011f1208e5062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f872c56fab94f73a1f3b9bb171e81e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3d7486adc54c849da4fdaf68d735e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7081df0ea46c4be4bc38a1b832289c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c9dd012dde4a138fb8a5c716d7feef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDMgSstPYv0P"
      },
      "source": [
        "# Text Classification:\n",
        "\n",
        "## Data\n",
        "<pre>\n",
        "1. we have total of 20 types of documents(Text files) and total 18828 documents(text files).\n",
        "2. You can download data from this <a href='https://drive.google.com/open?id=1rxD15nyeIPIAZ-J2VYPrDRZI66-TBWvM'>link</a>, in that you will get documents.rar folder. <br>If you unzip that, you will get total of 18828 documnets. document name is defined as'ClassLabel_DocumentNumberInThatLabel'. \n",
        "so from document name, you can extract the label for that document.\n",
        "4. Now our problem is to classify all the documents into any one of the class.\n",
        "5. Below we provided count plot of all the labels in our data. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64U9NzWFYv0V"
      },
      "source": [
        "### count plot of all the class labels. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAlyJhf3AZJl",
        "outputId": "732d6784-1b2e-474a-b1dc-cc2605a3d556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyunpack\n",
        "# !pip install patool"
      ],
      "metadata": {
        "id": "QNBP-KbZaxn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #https://stackoverflow.com/questions/50315989/how-to-extract-rar-files-inside-google-colab\n",
        "# from pyunpack import Archive\n",
        "# data_path_dir = '/content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata/documents.rar'\n",
        "# data_unzip_path_dir= '/content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata'\n",
        "# Archive(data_path_dir).extractall(data_unzip_path_dir)"
      ],
      "metadata": {
        "id": "HrDC9xsgagxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# text_data = \"path/to/text/data\" # Replace with the path to the directory containing text files\n",
        "text_data= r'/content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata/documents'\n",
        "texts = []\n",
        "labels = []\n",
        "label_index = {}\n",
        "label_id = 0\n",
        "\n",
        "# for fname in tqdm(sorted(os.listdir(text_data))):\n",
        "for fname in tqdm(os.listdir(text_data)[:10], desc=\"Processing files\"):\n",
        "\n",
        "    if fname.endswith(\".txt\"):\n",
        "        fpath = os.path.join(text_data, fname)\n",
        "        if sys.version_info < (3,):\n",
        "            f = open(fpath)\n",
        "        else:\n",
        "            f = open(fpath, encoding=\"latin-1\")\n",
        "        t = f.read()\n",
        "        texts.append(t)\n",
        "        label = fname.split(\"_\")[0]  # Assumes label is the prefix of the file name before \"_\"\n",
        "        if label not in label_index:\n",
        "            label_index[label] = label_id\n",
        "            label_id += 1\n",
        "        labels.append(label_index[label])\n",
        "print(\"*\" * 100)\n",
        "print('Length of Label index of dataset {}'.format(len(label_index)))\n",
        "print(\"-\" * 100)\n",
        "print('Label index of dataset {}'.format(label_index))\n",
        "print(\"-\" * 100)\n",
        "print('Length of texts: {} textfiles'.format(len(texts)))\n",
        "print(\"*\" * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "829caaa27e9c409aad0c75e28206f53f",
            "34dee9465d6f4ea78f57fa672b86d24f",
            "e8ae3dde63f74d66ab8f6558d70b14f3",
            "fe9e8d9ce70d45d1b3078995bc1d3f52",
            "1a588121bad54354bcea11fd008c75b9",
            "5f933a3b22f9455a8046392d8893330b",
            "ec18a3fb1a094f2faaeed274db038fd2",
            "26f6b34dea0c4872b421ab6b21ffd4f7",
            "4f44ff6b99044f6698839e2cc68aba1a",
            "2cf556d0b3c44d58a3fa3b9310abd436",
            "937cfc82d8784377b1e1d12a274a128e"
          ]
        },
        "id": "R8ufa2k0afsT",
        "outputId": "e761be61-3bf8-496e-acab-43c3881d7886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing files:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "829caaa27e9c409aad0c75e28206f53f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "Length of Label index of dataset 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Label index of dataset {'talk.politics.misc': 0}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Length of texts: 10 textfiles\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[5])"
      ],
      "metadata": {
        "id": "2tnnAgQxeWvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa28ee17-5e26-491a-f455-b29790ddef18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: steveh@thor.isc-br.com (Steve Hendricks)\n",
            "Subject: Re: Limiting Govt (Was Re: Employment (was Re: Why not concentrate...)\n",
            "\n",
            "In article <SLAGLE.93Apr15000157@sgi417.msd.lmsc.lockheed.com> slagle@lmsc.lockheed.com writes:\n",
            ">In article <1993Apr13.215245.2916@isc-br.isc-br.com>, steveh@thor.isc-br.com (Steve Hendricks) writes:\n",
            ">\n",
            ">> In article <1993Apr13.083449.1058@cbnewse.cb.att.com> doctor1@cbnewse.cb.att.com (patrick.b.hailey) writes:\n",
            ">\n",
            ">>>... the point is that this law protects no one but the\n",
            ">>>established car dealers or people with enough money to start a\n",
            ">>>fairly big operation all at once.  Protecting these folks from\n",
            ">>>competition protects the rest of us from low prices and high\n",
            ">>>quality.\n",
            ">\n",
            ">> An excellent point.  But you seem to be missing a more subtle\n",
            ">> point.  It is not \"the government\" that should be the recipient\n",
            ">> of your displeasure, but the established business interests\n",
            ">> that influence and direct government action in this case.\n",
            ">\n",
            ">It is the government that is preventing entry to the market.  The\n",
            ">desire of those running established businesses to prevent or\n",
            ">restrict the entry of competitors is an understandable, though\n",
            ">generally unpleasant, human failing.  But without a means to act\n",
            ">on this desire, without a government with sufficient power to\n",
            ">restrict the options of the potential competitor, the\n",
            ">anti-competitive desire remains just an unpleasant wish.  The\n",
            ">government is the linchpin, so we seek to disengage it so we\n",
            ">don't get the shaft.\n",
            "\n",
            "Once again, Mark, you don't specify the means through which the government\n",
            "is to be prevented from becoming the tool of business interests.  As a \n",
            "left-wing, big government, conventional liberal, I'm just as willing as\n",
            "you are to vote against anti-competitive regulations that favor auto\n",
            "dealers.  \n",
            "\n",
            "But what I hear from libertarians is a desire to limit incumbents' terms,\n",
            "to weaken government by eliminating its power to enforce antitrust laws,\n",
            "and a desire to eliminate legislator's pay.  Each strikes me as a \n",
            "particularly ineffective way to insure that auto dealers and other special\n",
            "interests cannot influence public policy.  In fact, they seem clearly\n",
            "designed to accomplish the opposite.\n",
            "\n",
            "jsh\n",
            ">\n",
            ">=Mark\n",
            "--\n",
            "Steve Hendricks                        |  DOMAIN:  steveh@thor.ISC-BR.COM   \n",
            "\"One thing about data, it sure does cut|  UUCP:    ...!uunet!isc-br!thor!steveh\n",
            " the bulls**t.\" - R. Hofferbert        |  Ma Bell: 509 838-8826\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting data into dataframes\n",
        "import pandas as pd\n",
        "# create dataframe\n",
        "df = pd.DataFrame({'text': texts, 'label': labels})\n",
        "# print dataframe\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4IojPxb3pcS",
        "outputId": "c0cf49c3-45ad-402a-deca-7b6b31b5f8c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  From: PA146008@utkvm1.utk.edu (David Veal)\\nSu...      0\n",
            "1  From: lfoard@hopper.Virginia.EDU (Lawrence C. ...      0\n",
            "2  From: jmorriso@rflab.ee.ubc.ca (John Paul Morr...      0\n",
            "3  From: gemmellj@merrimack.edu\\nSubject: e-mail ...      0\n",
            "4  From: as010b@uhura.cc.rochester.edu (Tree of S...      0\n",
            "5  From: steveh@thor.isc-br.com (Steve Hendricks)...      0\n",
            "6  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...      0\n",
            "7  From: jlinder@magnus.acs.ohio-state.edu (Jeffr...      0\n",
            "8  From: nelson_p@apollo.hp.com (Peter Nelson)\\nS...      0\n",
            "9  From: gsh7w@fermi.clas.Virginia.EDU (Greg Henn...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fAgO6zlB4dAK",
        "outputId": "8df004c0-c9b1-4a9d-c33e-cb7fb6f317c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  From: PA146008@utkvm1.utk.edu (David Veal)\\nSu...      0\n",
              "1  From: lfoard@hopper.Virginia.EDU (Lawrence C. ...      0\n",
              "2  From: jmorriso@rflab.ee.ubc.ca (John Paul Morr...      0\n",
              "3  From: gemmellj@merrimack.edu\\nSubject: e-mail ...      0\n",
              "4  From: as010b@uhura.cc.rochester.edu (Tree of S...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c98b16ee-3187-4e84-b637-3fe2c43d6896\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: PA146008@utkvm1.utk.edu (David Veal)\\nSu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: lfoard@hopper.Virginia.EDU (Lawrence C. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: jmorriso@rflab.ee.ubc.ca (John Paul Morr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: gemmellj@merrimack.edu\\nSubject: e-mail ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: as010b@uhura.cc.rochester.edu (Tree of S...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c98b16ee-3187-4e84-b637-3fe2c43d6896')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c98b16ee-3187-4e84-b637-3fe2c43d6896 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c98b16ee-3187-4e84-b637-3fe2c43d6896');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pEZ-Q0jJaCN",
        "outputId": "46a3a3c4-970d-4f19-b076-df4d35b130c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4ZePBReJZsX",
        "outputId": "1686da08-1694-40a1-e48f-3bb26563ee20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     From: steveh@thor.isc-br.com (Steve Hendricks)...\n",
              "label                                                    0\n",
              "Name: 5, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mK4TJOFYv0h"
      },
      "source": [
        "## Assignment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlqYFVI3Yv0k"
      },
      "source": [
        "#### sample document\n",
        "<pre>\n",
        "<font color='blue'>\n",
        "Subject: A word of advice\n",
        "From: jcopelan@nyx.cs.du.edu (The One and Only)\n",
        "\n",
        "In article < 65882@mimsy.umd.edu > mangoe@cs.umd.edu (Charley Wingate) writes:\n",
        ">\n",
        ">I've said 100 times that there is no \"alternative\" that should think you\n",
        ">might have caught on by now.  And there is no \"alternative\", but the point\n",
        ">is, \"rationality\" isn't an alternative either.  The problems of metaphysical\n",
        ">and religious knowledge are unsolvable-- or I should say, humans cannot\n",
        ">solve them.\n",
        "\n",
        "How does that saying go: Those who say it can't be done shouldn't interrupt\n",
        "those who are doing it.\n",
        "\n",
        "Jim\n",
        "--\n",
        "Have you washed your brain today?\n",
        "</font>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAR5HoR1Yv0m"
      },
      "source": [
        "### Preprocessing:\n",
        "<pre>\n",
        "useful links: <a href='http://www.pyregex.com/'>http://www.pyregex.com/</a>\n",
        "\n",
        "<font color='blue'><b>1.</b></font> Find all emails in the document and then get the text after the \"@\". and then split those texts by '.' \n",
        "after that remove the words whose length is less than or equal to 2 and also remove'com' word and then combine those words by space. \n",
        "In one doc, if we have 2 or more mails, get all.\n",
        "<b>Eg:[test@dm1.d.com, test2@dm2.dm3.com]-->[dm1.d.com, dm3.dm4.com]-->[dm1,d,com,dm2,dm3,com]-->[dm1,dm2,dm3]-->\"dm1 dm2 dm3\" </b> \n",
        "append all those into one list/array. ( This will give length of 18828 sentences i.e one list for each of the document). \n",
        "Some sample output was shown below. \n",
        "\n",
        "> In the above sample document there are emails [jcopelan@nyx.cs.du.edu, 65882@mimsy.umd.edu, mangoe@cs.umd.edu]\n",
        "\n",
        "preprocessing:\n",
        "[jcopelan@nyx.cs.du.edu, 65882@mimsy.umd.edu, mangoe@cs.umd.edu] ==> [nyx cs du edu mimsy umd edu cs umd edu] ==> \n",
        "[nyx edu mimsy umd edu umd edu]\n",
        "\n",
        "<font color='blue'><b>2.</b></font> Replace all the emails by space in the original text. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIovFDQzYv03"
      },
      "source": [
        "<pre>\n",
        "<font color='blue'><b>3.</b></font> Get subject of the text i.e. get the total lines where \"Subject:\" occur and remove \n",
        "the word which are before the \":\" remove the newlines, tabs, punctuations, any special chars.\n",
        "<b>Eg: if we have sentance like \"Subject: Re: Gospel Dating @ \\r\\r\\n\" --> You have to get \"Gospel Dating\"</b> \n",
        "Save all this data into another list/array. \n",
        "\n",
        "<font color='blue'><b>4.</b></font> After you store it in the list, Replace those sentances in original text by space.\n",
        "\n",
        "<font color='blue'><b>5.</b></font> Delete all the sentances where sentence starts with <b>\"Write to:\"</b> or <b>\"From:\"</b>.\n",
        "> In the above sample document check the 2nd line, we should remove that\n",
        "\n",
        "<font color='blue'><b>6.</b></font> Delete all the tags like \"< anyword >\"\n",
        "> In the above sample document check the 4nd line, we should remove that \"< 65882@mimsy.umd.edu >\"\n",
        "\n",
        "\n",
        "<font color='blue'><b>7.</b></font> Delete all the data which are present in the brackets. \n",
        "In many text data, we observed that, they maintained the explanation of sentence \n",
        "or translation of sentence to another language in brackets so remove all those.\n",
        "<b>Eg: \"AAIC-The course that gets you HIRED(AAIC - Der Kurs, der Sie anstellt)\" --> \"AAIC-The course that gets you HIRED\"</b>\n",
        "\n",
        "> In the above sample document check the 4nd line, we should remove that \"(Charley Wingate)\"\n",
        "\n",
        "\n",
        "<font color='blue'><b>8.</b></font> Remove all the newlines('\\n'), tabs('\\t'), \"-\", \"\\\".\n",
        "\n",
        "<font color='blue'><b>9.</b></font> Remove all the words which ends with <b>\":\"</b>.\n",
        "<b>Eg: \"Anyword:\"</b>\n",
        "> In the above sample document check the 4nd line, we should remove that \"writes:\"\n",
        "\n",
        "\n",
        "<font color='blue'><b>10.</b></font> Decontractions, replace words like below to full words. \n",
        "please check the donors choose preprocessing for this \n",
        "<b>Eg: can't -> can not, 's -> is, i've -> i have, i'm -> i am, you're -> you are, i'll --> i will </b>\n",
        "\n",
        "<b> There is no order to do point 6 to 10. but you have to get final output correctly</b>\n",
        "\n",
        "<font color='blue'><b>11.</b></font> Do chunking on the text you have after above preprocessing. \n",
        "Text chunking, also referred to as shallow parsing, is a task that \n",
        "follows Part-Of-Speech Tagging and that adds more structure to the sentence.\n",
        "So it combines the some phrases, named entities into single word.\n",
        "So after that combine all those phrases/named entities by separating <b>\"_\"</b>. \n",
        "And remove the phrases/named entities if that is a \"Person\". \n",
        "You can use <b>nltk.ne_chunk</b> to get these. \n",
        "Below we have given one example. please go through it. \n",
        "\n",
        "useful links: \n",
        "<a href='https://www.nltk.org/book/ch07.html'>https://www.nltk.org/book/ch07.html</a>\n",
        "<a href='https://stackoverflow.com/a/31837224/4084039'>https://stackoverflow.com/a/31837224/4084039</a>\n",
        "<a href='http://www.nltk.org/howto/tree.html'>http://www.nltk.org/howto/tree.html</a>\n",
        "<a href='https://stackoverflow.com/a/44294377/4084039'>https://stackoverflow.com/a/44294377/4084039</a>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lAaKQ6EYv04",
        "outputId": "c4f0527c-3ea8-41b7-e3bb-5ff0ff511d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#i am living in the New York\n",
        "print(\"i am living in the New York -->\", list(chunks))\n",
        "print(\" \")\n",
        "print(\"-\"*50)\n",
        "print(\" \")\n",
        "#My name is Srikanth Varma\n",
        "print(\"My name is Srikanth Varma -->\", list(chunks1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3430b9a6ac86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#i am living in the New York\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i am living in the New York -->\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'chunks' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV8gzLUjYv0-"
      },
      "source": [
        "<pre>We did chunking for above two lines and then We got one list where each word is mapped to a \n",
        "POS(parts of speech) and also if you see \"New York\" and \"Srikanth Varma\", \n",
        "they got combined and represented as a tree and \"New York\" was referred as \"GPE\" and \"Srikanth Varma\" was referred as \"PERSON\". \n",
        "so now you have to Combine the \"New York\" with <b>\"_\"</b> i.e \"New_York\"\n",
        "and remove the \"Srikanth Varma\" from the above sentence because it is a person.</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpaC-KF3Yv1A"
      },
      "source": [
        "<pre>\n",
        "<font color='blue'><b>13.</b></font> Replace all the digits with space i.e delete all the digits. \n",
        "> In the above sample document, the 6th line have digit 100, so we have to remove that.\n",
        "\n",
        "<font color='blue'><b>14.</b></font> After doing above points, we observed there might be few word's like\n",
        " <b> \"_word_\" (i.e starting and ending with the _), \"_word\" (i.e starting with the _),\n",
        "  \"word_\" (i.e ending with the _)</b> remove the <b>_</b> from these type of words. \n",
        "\n",
        "<font color='blue'><b>15.</b></font>  We also observed some words like <b> \"OneLetter_word\"- eg: d_berlin, \n",
        "\"TwoLetters_word\" - eg: dr_berlin </b>, in these words we remove the \"OneLetter_\" (d_berlin ==> berlin) and \n",
        "\"TwoLetters_\" (de_berlin ==> berlin). i.e remove the words \n",
        "which are length less than or equal to 2 after spliiting those words by \"_\". \n",
        "\n",
        "<font color='blue'><b>16.</b></font> Convert all the words into lower case and lowe case \n",
        "and remove the words which are greater than or equal to 15 or less than or equal to 2.\n",
        "\n",
        "<font color='blue'><b>17.</b></font> replace all the words except \"A-Za-z_\" with space. \n",
        "\n",
        "<font color='blue'><b>18.</b></font> Now You got Preprocessed Text, email, subject. create a dataframe with those. \n",
        "Below are the columns of the df. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfWUeIN1Yv1N"
      },
      "source": [
        "### To get above mentioned data frame --> Try to Write Total Preprocessing steps in One Function Named Preprocess as below. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4NBhSnoLjIi",
        "outputId": "4e44a836-4350-4348-c51e-d2387e7e9b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-2.0.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "import contractions\n",
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "W0548TDy2jKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2ffd83-47de-41f8-ca8e-071401b416c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Master piece\n",
        "def preprocess(Input_Text):\n",
        "    \"\"\"Do all the Preprocessing as shown above and\n",
        "    return a tuple contain preprocess_email,preprocess_subject,preprocess_text for that Text_data\"\"\"\n",
        "\n",
        "    def s1(text):\n",
        "        # Find all email addresses in the text\n",
        "        emails = re.findall(r'\\S+@\\S+', text)\n",
        "        # print(emails)\n",
        "        \n",
        "        # Get the domain names from each email and split by '.'\n",
        "        # domains = [email.split('@')[1].split('.') for email in emails]\n",
        "        # Extract the domain after the '@' symbol\n",
        "        # domain = email.split('@')[1]\n",
        "        domains = []\n",
        "        for email in emails:\n",
        "            if '<' in email and '>' in email:\n",
        "                domain = email.split('@')[1].split('>')[0]\n",
        "              \n",
        "            else:\n",
        "                domain = email.split('@')[1]\n",
        "            domains.append(domain)\n",
        "        # print(domains)\n",
        "        # Remove words with length <= 2 and 'com' from each domain\n",
        "        filtered_domains = [[word for word in domain.split('.') if len(word) > 2 and word != 'com'] for domain in domains]\n",
        "        # print(filtered_domains)\n",
        "        # Flatten the list of domains and join by space\n",
        "        combined_domains = ' '.join([word for domain in filtered_domains for word in domain])\n",
        "        # print(combined_domains)\n",
        "        # Replace all email addresses with a space\n",
        "        for email in emails:\n",
        "            text = text.replace(email, ' ')\n",
        "        # print(text)\n",
        "        return combined_domains, text\n",
        "\n",
        "    preprocessed_emails, text1 = s1(Input_Text)\n",
        "\n",
        "    def s3(text):  #step-3 and step-4\n",
        "        # get subject of the text\n",
        "        # subject_lines = [line for line in text.split(\"\\n\") if \"Subject:\" in line]\n",
        "        # # Extract the lines starting with \"Subject:\"\n",
        "        # subject_lines = [line for line in text.split('\\n') if line.startswith('Subject:')]\n",
        "        # subjects = [re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", line.split(\":\")[1].strip()) for line in subject_lines]\n",
        "\n",
        "        # # replace subject lines in original text\n",
        "        # for line in subject_lines:\n",
        "        #     text = text.replace(line, \"\")\n",
        " \n",
        "        subject = re.search(r'Subject:\\s*(.*)', text).group(1)\n",
        "        subject = re.sub(r'[^\\w\\s]', '', subject)\n",
        "        subject = re.sub(r'[\\n\\t]', '', subject)\n",
        "        # subject = re.sub(r'^\\s*(Re)?\\s*', '', subject)\n",
        "        subject = re.sub(r'\\b[rR][eE]?\\b', '', subject)\n",
        "        text = re.sub(r'Subject:.+\\n', '', text)\n",
        "\n",
        "        return subject, text\n",
        "\n",
        "        # subject = re.search(r'Subject:\\s*(.*)', text)\n",
        "        # remove punctuations, special characters, tabs, and newlines\n",
        "\n",
        "        # subject = re.sub(r'[^\\w\\s]', '', subject)\n",
        "        # subject = re.sub(r'[\\n\\t]', '', subject)\n",
        "        # subject = re.sub(r'^\\s*(Re)?\\s*', '', subject)\n",
        "        # subject = re.sub(r'\\b[rR][eE]?\\b', '', subject)\n",
        "        # text = re.sub(r'Subject:.+\\n', '', text)\n",
        "\n",
        "        # return subject, text\n",
        "\n",
        "    subject, text2 = s3(text1)\n",
        "    def s5(text):\n",
        "        # Step 4: Delete all the sentences starting with \"Write to:\" or \"From:\"\n",
        "        text_a = re.sub(r'^(Write to:|From:).*\\n?', '', text, flags=re.MULTILINE)\n",
        "\n",
        "        # Step 2: Delete all the tags like \"< anyword >\"\n",
        "        text_b = re.sub(r'<[^>]*>', '', text_a)\n",
        "\n",
        "        # Step 3: Delete all the data present in brackets\n",
        "        text_c = re.sub(r'\\(.*?\\)', '', text_b)\n",
        "\n",
        "        # Step 4: Remove all the newlines, tabs, \"-\", \"\\\"\n",
        "        text_d = re.sub(r'[\\n\\t\\\\-]', '', text_c)\n",
        "\n",
        "        # Step 5: Remove all the words ending with \":\"\n",
        "        text_e = re.sub(r'\\b\\w+:\\b', '', text_d)\n",
        "\n",
        "\n",
        "        return text_e\n",
        "    text3 = s5(text2)\n",
        "    def s10(text):\n",
        "    #Step-10: Decontractions, replace words like below to full words.\n",
        "    #https://www.geeksforgeeks.org/nlp-expand-contractions-in-text-processing/\n",
        "        text = contractions.fix(text)\n",
        "        return text\n",
        "\n",
        "    text4 = s10(text3)\n",
        "\n",
        "\n",
        "\n",
        "    def s11(text):\n",
        "    # step-11: Text chunking\n",
        "    # function to chunk the text and combine phrases/named entities with \"_\" and remove Person entity\n",
        "    # tokenizing the text\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "        # POS tagging\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "        # chunking the named entities\n",
        "        chunks = nltk.ne_chunk(pos_tags, binary=False)\n",
        "        # combining phrases/named entities with \"_\"\n",
        "        combined_chunks = []\n",
        "        current_chunk = []\n",
        "        for subtree in chunks:\n",
        "            if type(subtree) == nltk.tree.Tree:\n",
        "                current_chunk.append(\"_\".join([token for token, pos in subtree.leaves()]))\n",
        "            elif current_chunk:\n",
        "                combined_chunk = \" \".join(current_chunk)\n",
        "                combined_chunks.append(combined_chunk)\n",
        "                current_chunk = []\n",
        "            else:\n",
        "                combined_chunks.append(subtree[0])\n",
        "        if current_chunk:\n",
        "            combined_chunk = \" \".join(current_chunk)\n",
        "            combined_chunks.append(combined_chunk)\n",
        "        # removing the \"PERSON\" named entities\n",
        "        combined_chunks_text = [chunk for chunk in combined_chunks if \"_PERSON\" not in chunk]\n",
        "        # combined_chunks_text = [' '.join(combined_chunks_text) for i in combined_chunks_text]\n",
        "        combined_chunks_text = ' '.join(map(str,combined_chunks_text))\n",
        "        \n",
        "        return combined_chunks_text\n",
        "\n",
        "    text5 = s11(text4)\n",
        "\n",
        "    def s13(text):\n",
        "        # step-13: replace digits with space\n",
        "        text = re.sub(r\"\\d+\", \" \", text)\n",
        "\n",
        "        # step-14: remove \"_\" from word starting with and ending with  of words\n",
        "        text = re.sub(r\"\\b_([a-zA-Z]+)_\\b\", r\"\\1\", text)\n",
        "        text = re.sub(r\"\\b_([a-zA-Z]+)\", r\"\\1\", text)\n",
        "        text = re.sub(r\"([a-zA-Z]+)_\\b\", r\"\\1\", text)\n",
        "\n",
        "        # step-15: remove \"OneLetter_\" and \"TwoLetters_\" from words from text\n",
        "        words = text.split()\n",
        "        processed_words = []\n",
        "        for word in words:\n",
        "            sub_words = word.split(\"_\")\n",
        "            sub_words = [sw[2:] if len(sw) == 3 else sw for sw in sub_words]\n",
        "            sub_words = [sw[3:] if len(sw) == 4 else sw for sw in sub_words]\n",
        "            processed_words.append(\"_\".join(sub_words))\n",
        "        text = \" \".join(processed_words)\n",
        "\n",
        "        #step-16: convert to lower case and remove words with length >= 15 or <= 2\n",
        "        text = \" \".join([w.lower() for w in text.split() if 2 < len(w) < 15])\n",
        "\n",
        "        #step-17: replace all non-alphanumeric and \"_\" with space\n",
        "        text = re.sub(r\"[^a-zA-Z_]+\", \" \", text)\n",
        "\n",
        "        return text\n",
        "    text6 = s13(text5) \n",
        "\n",
        "\n",
        "    return (preprocessed_emails,subject,text6)"
      ],
      "metadata": {
        "id": "6LnDwkyYUeJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceASjKizYv1U"
      },
      "source": [
        "### Code checking:\n",
        "\n",
        "<font color='red' size=4>\n",
        "After Writing preprocess function. call that functoin with the input text of 'alt.atheism_49960' doc and print the output of the preprocess function\n",
        "<br>\n",
        "This will help us to evaluate faster, based on the output we can suggest you if there are any changes.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_txt = 'alt.atheism_49960'\n",
        "# file_path = '/content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata/documents/alt.atheism_49960.txt'\n",
        "file_path =  '/content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata/documents/comp.graphics_38342.txt'\n",
        "with open(file_path,  encoding=\"latin\", errors='ignore') as f: #encoding='latin-1'  utf8\n",
        "    eval_data = f.read().replace('\\n', '')\n",
        "# print(eval_data)\n",
        "preprocess(eval_data)"
      ],
      "metadata": {
        "id": "yD33UpoG2bG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5938445f-7a2c-4988-bb30-7c4b3f59b379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hydra unm edu hydra unm edu',\n",
              " 'polygon orientation in DXFHi  Im writing a program to convert dxf files to a databaseformat used by a 3D graphics program Ive written  My program storesthe points of a polygon in CCW order  Ive used 3D Concepts a little and it seems that the points are stored in the orderthey are drawnDoes the DXF format have a way of indicating which order the points are stored in CW or CCW  Its easy enough to convertbut if I dont know which way they are stored I dont know which direction the polygon should be visible fromIf DXF doesnt handle this can anyone recommend a workaroundThe best I can think of is to create two polygons for each onein the DXF file one stored CW and the other CCW  But thatdoubles the number of polygons and decreases speedThanks in advance for any helpPatrice  ',\n",
              " '')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x3og_iaYv1S"
      },
      "source": [
        "### After writing Preprocess function, call the function for each of the document(18828 docs) and then create a dataframe as mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_preprocessed_emails = []\n",
        "subject = []\n",
        "cleaned_text = []\n",
        "# iterate through rows and apply function\n",
        "for index, row in tqdm(df.iterrows(),total=len(df)):\n",
        "    a,b,c = preprocess(row['text'])\n",
        "    cleaned_text.append(c)\n",
        "    df.at[index, 'preprocessed_text'] = c    #https://www.geeksforgeeks.org/python-pandas-dataframe-at/\n",
        "    # list_of_preprocessed_emails.append(' '.join(a))\n",
        "    df.at[index, 'preprocessed_emails'] = a\n",
        "    list_of_preprocessed_emails.append(a)\n",
        "    subject.append(b)\n",
        "    df.at[index, 'preprocessed_subject'] = b\n",
        "    \n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768,
          "referenced_widgets": [
            "b3acc1db1c9d46c4b1985c13581fbb8c",
            "8c8d01edbcc64a4f9ff6a69be3e33fb2",
            "f61d16c0b02247838d929d9b2b3f3e91",
            "628ec3989da242d1b675fb5d5eefee17",
            "4c6e5c064f154e938420b987513009f5",
            "8086a626076540a59f09e140fa31227d",
            "cae8b9217c0f489ba727d5f6d9fb53ca",
            "75c22de6e2a84c5a9a8e52f34d445269",
            "01bafba4addd47e09da2905d932c02ff",
            "836ffa74979b4cf2a31834d7b2288795",
            "ca564868b3934f8cad8e03cec3409e08"
          ]
        },
        "outputId": "b42cc0af-3ae1-4dc4-c876-ca2f14ba7343",
        "id": "IV-wX_u-D6-W"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3acc1db1c9d46c4b1985c13581fbb8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label  \\\n",
              "0  From: PA146008@utkvm1.utk.edu (David Veal)\\nSu...      0   \n",
              "1  From: lfoard@hopper.Virginia.EDU (Lawrence C. ...      0   \n",
              "2  From: jmorriso@rflab.ee.ubc.ca (John Paul Morr...      0   \n",
              "3  From: gemmellj@merrimack.edu\\nSubject: e-mail ...      0   \n",
              "4  From: as010b@uhura.cc.rochester.edu (Tree of S...      0   \n",
              "5  From: steveh@thor.isc-br.com (Steve Hendricks)...      0   \n",
              "6  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...      0   \n",
              "7  From: jlinder@magnus.acs.ohio-state.edu (Jeffr...      0   \n",
              "8  From: nelson_p@apollo.hp.com (Peter Nelson)\\nS...      0   \n",
              "9  From: gsh7w@fermi.clas.Virginia.EDU (Greg Henn...      0   \n",
              "\n",
              "                                   preprocessed_text  \\\n",
              "0  article writes article writes article writes s...   \n",
              "1  article writes article wrence foard writes art...   \n",
              "2  article writes likely places there important s...   \n",
              "3  clinton email wondering congress alsogoing any...   \n",
              "4  writes article writes article writes however m...   \n",
              "5  article writes article writes article writes p...   \n",
              "6  writes writes world future l_clinton appoint c...   \n",
              "7  article writes article koppenhoefer cramm writ...   \n",
              "8  article writes article writes critisism soluti...   \n",
              "9  clayton cramer compared table already posted m...   \n",
              "\n",
              "                                 preprocessed_emails  \\\n",
              "0  utkvm1 utk edu dscomsa desy dscomsa desy utkvm...   \n",
              "1  hopper Virginia EDU magnus acs ohio-state edu ...   \n",
              "2        rflab ubc rigel tamu edu rigel tamu edu ubc   \n",
              "3                                      merrimack edu   \n",
              "4  uhura rochester edu optilink COM optilink COM ...   \n",
              "5  thor isc-br sgi417 msd lmsc lockheed lmsc lock...   \n",
              "6  cunixb columbia edu phoneme harvard edu sandba...   \n",
              "7  magnus acs ohio-state edu midway uchicago edu ...   \n",
              "8  apollo ctron-news ctron ctron news cso uiuc ed...   \n",
              "9               fermi clas Virginia EDU virginia edu   \n",
              "\n",
              "                                preprocessed_subject  \n",
              "0                           Propaganda   fillibuster  \n",
              "1                    New Study Out On Gay Percentage  \n",
              "2   Limiting Govt was  Employment was  Why not co...  \n",
              "3                                 email to the hill   \n",
              "4             Why not concentrate on child molesters  \n",
              "5   Limiting Govt Was  Employment was  Why not co...  \n",
              "6                            The Manitoban Candidate  \n",
              "7                              Kyle K on Rodney King  \n",
              "8                        Welcome to Police State USA  \n",
              "9                    New Study Out On Gay Percentage  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea64b099-bbae-40ea-aead-e72aaf31b210\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>preprocessed_emails</th>\n",
              "      <th>preprocessed_subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: PA146008@utkvm1.utk.edu (David Veal)\\nSu...</td>\n",
              "      <td>0</td>\n",
              "      <td>article writes article writes article writes s...</td>\n",
              "      <td>utkvm1 utk edu dscomsa desy dscomsa desy utkvm...</td>\n",
              "      <td>Propaganda   fillibuster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: lfoard@hopper.Virginia.EDU (Lawrence C. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>article writes article wrence foard writes art...</td>\n",
              "      <td>hopper Virginia EDU magnus acs ohio-state edu ...</td>\n",
              "      <td>New Study Out On Gay Percentage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: jmorriso@rflab.ee.ubc.ca (John Paul Morr...</td>\n",
              "      <td>0</td>\n",
              "      <td>article writes likely places there important s...</td>\n",
              "      <td>rflab ubc rigel tamu edu rigel tamu edu ubc</td>\n",
              "      <td>Limiting Govt was  Employment was  Why not co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: gemmellj@merrimack.edu\\nSubject: e-mail ...</td>\n",
              "      <td>0</td>\n",
              "      <td>clinton email wondering congress alsogoing any...</td>\n",
              "      <td>merrimack edu</td>\n",
              "      <td>email to the hill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: as010b@uhura.cc.rochester.edu (Tree of S...</td>\n",
              "      <td>0</td>\n",
              "      <td>writes article writes article writes however m...</td>\n",
              "      <td>uhura rochester edu optilink COM optilink COM ...</td>\n",
              "      <td>Why not concentrate on child molesters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>From: steveh@thor.isc-br.com (Steve Hendricks)...</td>\n",
              "      <td>0</td>\n",
              "      <td>article writes article writes article writes p...</td>\n",
              "      <td>thor isc-br sgi417 msd lmsc lockheed lmsc lock...</td>\n",
              "      <td>Limiting Govt Was  Employment was  Why not co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
              "      <td>0</td>\n",
              "      <td>writes writes world future l_clinton appoint c...</td>\n",
              "      <td>cunixb columbia edu phoneme harvard edu sandba...</td>\n",
              "      <td>The Manitoban Candidate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From: jlinder@magnus.acs.ohio-state.edu (Jeffr...</td>\n",
              "      <td>0</td>\n",
              "      <td>article writes article koppenhoefer cramm writ...</td>\n",
              "      <td>magnus acs ohio-state edu midway uchicago edu ...</td>\n",
              "      <td>Kyle K on Rodney King</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>From: nelson_p@apollo.hp.com (Peter Nelson)\\nS...</td>\n",
              "      <td>0</td>\n",
              "      <td>article writes article writes critisism soluti...</td>\n",
              "      <td>apollo ctron-news ctron ctron news cso uiuc ed...</td>\n",
              "      <td>Welcome to Police State USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>From: gsh7w@fermi.clas.Virginia.EDU (Greg Henn...</td>\n",
              "      <td>0</td>\n",
              "      <td>clayton cramer compared table already posted m...</td>\n",
              "      <td>fermi clas Virginia EDU virginia edu</td>\n",
              "      <td>New Study Out On Gay Percentage</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea64b099-bbae-40ea-aead-e72aaf31b210')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea64b099-bbae-40ea-aead-e72aaf31b210 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea64b099-bbae-40ea-aead-e72aaf31b210');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUEZDDUjJ_9-",
        "outputId": "b8468b08-0359-4112-d2b6-c2f0a22611ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label', 'preprocessed_text', 'preprocessed_emails',\n",
              "       'preprocessed_subject'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEmSGNYwKDCA",
        "outputId": "0deb3547-db02-42e7-ce52-6c7390249380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                    From: steveh@thor.isc-br.com (Steve Hendricks)...\n",
              "label                                                                   0\n",
              "preprocessed_text       article writes article writes article writes p...\n",
              "preprocessed_emails     thor isc-br sgi417 msd lmsc lockheed lmsc lock...\n",
              "preprocessed_subject     Limiting Govt Was  Employment was  Why not co...\n",
              "Name: 5, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ucJLtWYv1V"
      },
      "source": [
        "### Training The models to Classify: \n",
        "\n",
        "<pre>\n",
        "1. Combine \"preprocessed_text\", \"preprocessed_subject\", \"preprocessed_emails\" into one column. use that column to model. \n",
        "\n",
        "2. Now Split the data into Train and test. use 25% for test also do a stratify split. \n",
        "\n",
        "3. Analyze your text data and pad the sequnce if required. \n",
        "Sequnce length is not restricted, you can use anything of your choice. \n",
        "you need to give the reasoning\n",
        "\n",
        "4. Do Tokenizer i.e convert text into numbers. please be careful while doing it. \n",
        "if you are using tf.keras \"Tokenizer\" API, it removes the <b>\"_\"</b>, but we need that.\n",
        "\n",
        "5. code the model's ( Model-1, Model-2 ) as discussed below \n",
        "and try to optimize that models.  \n",
        "\n",
        "6. For every model use predefined Glove vectors. \n",
        "<b>Don't train any word vectors while Training the model.</b>\n",
        "\n",
        "7. Use \"categorical_crossentropy\" as Loss. \n",
        "\n",
        "8. Use <b>Accuracy and Micro Avgeraged F1 score</b> as your as Key metrics to evaluate your model. \n",
        "\n",
        "9.  Use Tensorboard to plot the loss and Metrics based on the epoches.\n",
        "\n",
        "10. Please save your best model weights in to <b>'best_model_L.h5' ( L = 1 or 2 )</b>. \n",
        "\n",
        "11. You are free to choose any Activation function, learning rate, optimizer.\n",
        "But have to use the same architecture which we are giving below.\n",
        "\n",
        "12. You can add some layer to our architecture but you <b>deletion</b> of layer is not acceptable.\n",
        "\n",
        "13. Try to use <b>Early Stopping</b> technique or any of the callback techniques that you did in the previous assignments.\n",
        "\n",
        "14. For Every model save your model to image ( Plot the model) with shapes \n",
        "and inlcude those images in the notebook markdown cell, \n",
        "upload those imgages to Classroom. You can use \"plot_model\" \n",
        "please refer <a href='https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model'>this</a> if you don't know how to plot the model with shapes. \n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt # importing the libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPool2D, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
        "from keras.layers import MaxPool1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "5yS1HFyLFRid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Installation and unzipping procedure of Glove vectors file\"\"\"\n",
        "# http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# pwd\n",
        "# %cd /content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata\n",
        "# pwd\n",
        "# !unzip glove*.zip"
      ],
      "metadata": {
        "id": "YyHNzeKSFRaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://edumunozsala.github.io/BlogEms/jupyter/nlp/classification/embeddings/python/2020/08/15/Intro_NLP_WordEmbeddings_Classification.html\n",
        "#https://stackoverflow.com/questions/50060241/how-to-use-glove-word-embeddings-file-on-google-colaboratory\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "embeddings_index = {}\n",
        "path_dir_glove_vec = '/content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata'\n",
        "f = open(os.path.join(path_dir_glove_vec, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urvHNwYXFRLC",
        "outputId": "eb68993c-1cdf-4dc5-a7fb-55b2bc380911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded.shape, X_test_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "YQs18p2QRMyo",
        "outputId": "c8d722c1-eb9f-4252-d0be-a7cd285bd3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a37de0166012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_padded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_padded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#version -1\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "num_classes = 20\n",
        "#Step-1: Combine \"preprocessed_text\", \"preprocessed_subject\", \"preprocessed_emails\" into one column. use that column to model.\n",
        "df['combined_text'] = df['preprocessed_text'] + ' ' + df['preprocessed_subject'] + ' ' + df['preprocessed_emails']\n",
        "\n",
        "#step-2: Now Split the data into Train and test. use 25% for test also do a stratify split.\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['combined_text'], df['label'], test_size=0.25, stratify=df['label'], random_state=30)\n",
        "combined_text = df['combined_text'].tolist()\n",
        "#Step-3:Analyze data, if padding of the sequence  of text data required\n",
        "maxlen = max([len(x.split()) for x in combined_text])  # choose a max length for the sequence (max_len = 622)\n",
        "#Step-4: Do Tokenizer i.e convert text into numbers.\n",
        "#https://stackoverflow.com/questions/58591223/forcing-tensorflows-tokenizer-to-include-next-line-char\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n', lower=True, split=' ', oov_token=\"<OOV>\")  # excluding '_' to remian in sentences \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "#https://medium.com/@canerkilinc/padding-for-nlp-7dd8598c916a\n",
        "X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(X_train_sequences, maxlen=maxlen, padding='post', truncating='post')\n",
        "X_test_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_sequences, maxlen=maxlen, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "#one hot encoding \n",
        "y_train_ohe = to_categorical(y_train, num_classes)\n",
        "y_test_ohe = to_categorical(y_test, num_classes)\n",
        "# create the embedding matrix using GloVe\n",
        "#https://ai.stackexchange.com/questions/28564/how-to-determine-the-embedding-size#:~:text=If%20we're%20in%20a,and%20no%20less%20than%20600.\n",
        "#https://edumunozsala.github.io/BlogEms/jupyter/nlp/classification/embeddings/python/2020/08/15/Intro_NLP_WordEmbeddings_Classification.html\n",
        "#https://stackoverflow.com/questions/50060241/how-to-use-glove-word-embeddings-file-on-google-colaboratory\n",
        "embedding_dim = 300  # choose an embedding dimension\n",
        "word_index = tokenizer.word_index\n",
        "num_words = len(word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "# embedding_file = '/content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata/glove.6B.100d.txt'  # specify the path to the glove file\n",
        "embedding_file = '/content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata/glove.6B.300d.txt'  # specify the path to the glove file\n",
        "\n",
        "\n",
        "# with open(embedding_file, encoding='utf8') as f:\n",
        "#     for line in tqdm(f,desc=\"Processing lines\"):\n",
        "#         word, *vector = line.split()\n",
        "#         if word in word_index:\n",
        "#             idx = word_index[word]\n",
        "#             embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "with open(embedding_file, encoding='utf8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in tqdm(lines, desc=\"Processing lines\"):\n",
        "    word, *vector = line.split()\n",
        "    if word in word_index:\n",
        "        idx = word_index[word]\n",
        "        embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9438c32866d9408ba209b17b0dd7fe92",
            "2f8deb7eb76b43edb5d6b63cce7c3fdd",
            "e4209da1c89b441397fda8c9d67b5b9c",
            "7236576b32244aec90b0211cfd3c3ee6",
            "97eee71ac1de409593068dc6d4c98d9b",
            "a89354886b8f41728408bab45cb3a590",
            "d0d14754fb574ec0aac723a5386bbe74",
            "80a3b719592f474b86295d4fc18fe2a5",
            "2c568656887e4cad88d158d7f76ef0ee",
            "5ffdec3e8f404041824a7146f843807a",
            "5bdb7f678d3b4a0cbca82939e4e5f3ca"
          ]
        },
        "id": "D-XZpIU5Y4wo",
        "outputId": "e2258632-33dd-4e89-ad5c-1eacf3c63672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing lines:   0%|          | 0/400000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9438c32866d9408ba209b17b0dd7fe92"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_ohe.shape,y_test_ohe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiKNfCk3W1BB",
        "outputId": "47fee84e-4b8c-41b6-e555-201723cc9d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7, 20), (3, 20))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqeevEOqQrqy",
        "outputId": "e1454d7f-f6e0-41dc-aea8-994c7cfe5205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7,), (7,), (3,), (3,))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LADSObTmSDXh",
        "outputId": "69324541-577a-47fd-94f6-0d6181939b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7,)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7p4q63oSAwT",
        "outputId": "1ed3943f-b5a4-4c25-9073-cda3004f25a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  7,   4,   7,   4,   7,   4, 205, 206,  24,  55, 207,   9,  90,\n",
              "       208, 209,  91,  92, 210,  93, 211,  56,  33, 212,  94,  95,  34,\n",
              "       213,  96, 214, 215,  96, 216,  94,  95,  93,  97,  98, 217, 218,\n",
              "       219, 220, 221, 222,  57,  14,   9, 223,  25,  58, 224, 225,   9,\n",
              "        92,   8, 226,  59,   8, 227,  99,  35,  15, 228, 229,  33, 230,\n",
              "        17, 231,   8, 232, 100,  18, 233,   8, 234, 235,  57, 101, 236,\n",
              "       237, 238,  33, 239,  11, 240, 241,   9,  59,  60, 242, 243,  15,\n",
              "        97, 102,  26, 244, 245, 246, 247,  61, 248, 103, 249, 250, 251,\n",
              "       252, 104, 253, 254, 255, 256,  12, 257, 258,  62,  26,  35, 259,\n",
              "       260,  18, 261,  63,  36, 105, 106,  10,  11, 262, 263, 105, 106,\n",
              "        64, 107,   5,  10, 264, 265, 266, 267, 268,  58,  98, 269, 270,\n",
              "        63, 108, 108, 109, 271, 272, 273, 274, 275, 276,   5, 277, 278,\n",
              "       110, 111, 279, 280, 281, 282, 283, 284,  58, 285,  55, 286, 287,\n",
              "       112, 113, 114, 288, 289, 290, 291, 292,  65,  19,  18, 293, 294,\n",
              "       295, 115,  66, 296, 297,   5, 298, 299,  18, 300, 301,  14, 114,\n",
              "       302, 303, 304, 305, 306, 307,  11, 308, 309, 116,  67, 116, 310,\n",
              "        12, 117, 311, 312,  68, 313, 118, 119, 314,  35, 315, 316, 317,\n",
              "       318, 319, 320, 120, 321,  12, 322, 323, 121, 324,   6,  37, 325,\n",
              "         3,   6,   3,   6,   3,   6,  37,   3,   6,  38, 326,  37,   3,\n",
              "         6, 327,  17, 328, 329,  68, 330, 117, 331, 122,  26,  65,   3,\n",
              "         6,   3,   6, 332, 333, 334, 335, 336, 337,  69,  67,   3,   6,\n",
              "       338,  67,   3,   6,  37,   3,   6, 339, 340,   3, 341, 342, 343,\n",
              "       121,   3,   6, 344,   3,   3, 345,   3,   3, 346, 347,   3,   3,\n",
              "       348,   3,   3, 349, 122,   3,   3, 350,   3,   3,   5, 351,  17,\n",
              "       102, 352,  39, 353, 354,  39, 355, 356, 357,  40, 358,   3,   6,\n",
              "       123, 359, 360, 361, 362,  16, 124, 125, 363,  63,  12, 126, 364,\n",
              "       365, 366,  11, 127, 367, 368, 369, 370, 125, 371, 372, 373,  69,\n",
              "        12, 374, 128, 375, 376, 377, 128,   5,  10, 129, 130, 131,  10,\n",
              "        91, 129, 378,  59, 379, 380, 381, 382, 132, 383, 130, 131, 384,\n",
              "       133,  70,  14, 385, 386, 387, 388, 389,  65, 390,  69,  12, 391,\n",
              "       392,   8,  27, 393, 134,  14,  61,  12, 394, 395, 396, 124, 397,\n",
              "       135,  10,  71, 398, 399,  24,  11, 400, 401, 402, 403, 136, 404,\n",
              "       405, 137, 138,  12, 406, 139, 138, 137, 407,  66, 140, 408, 409,\n",
              "       410, 113,  62,  28,  27, 411, 412,  28, 413,  28,  20,  15,  20,\n",
              "       414,  15,  24,   8, 415,  99,  35, 416, 417, 418,  15, 112, 141,\n",
              "        66, 140,  15, 419,  24, 420, 421, 422, 423, 424, 425, 142, 426,\n",
              "        38, 427, 143, 428, 429,  36,   9,  28,  21,  20, 430, 431, 432,\n",
              "       144, 145,  57, 433, 434, 435,  21,  20,  14,   9,  21,  20, 436,\n",
              "       146, 146,   8, 437, 438,  21, 439,  25,  21,  20, 440,  21, 441,\n",
              "       442, 443, 444, 445, 446, 447,  72, 448, 449,  72, 450, 451, 452,\n",
              "       453, 454,  62,   5,  33,  72,  25, 147, 455, 456, 457, 458, 459,\n",
              "       460, 461, 462, 148,  36, 463, 148, 464,  17, 149, 144, 465, 466,\n",
              "        41,  41,   8,  24, 467, 468, 469, 470, 149,  36, 471, 472,  10,\n",
              "       150, 473, 474, 475,  10,  18, 151, 476, 115, 477,  26, 478, 479,\n",
              "        16,  10, 151,  64, 480, 150,  26, 481, 482, 483,  10,   9, 484,\n",
              "       485, 486, 487, 488, 489, 490, 126, 491, 492, 493,  73, 494, 495,\n",
              "       496, 497, 498,  64,  42,  43,   2,  44,  45,  44,  45,  42,  43,\n",
              "         2,  42,  43,   2,  44,  45,  44,  45,  42,  43,   2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.16.1\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh0--r8qfD2K",
        "outputId": "db67d35b-e9ee-4823-cb8b-fa46182ded98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons==0.16.1\n",
            "  Downloading tensorflow_addons-0.16.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons==0.16.1) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train is being tested by passing in the model\n",
        "X_train \n"
      ],
      "metadata": {
        "id": "MdM_bkc8N-hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model-1\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, Concatenate, MaxPooling1D, Flatten, Dropout, Dense\n",
        "\n",
        "# Hyperparameters\n",
        "embedding_dim = 300\n",
        "max_seq_length = maxlen #622\n",
        "num_filters = 16\n",
        "filter_sizes = [3, 4, 5]\n",
        "num_classes = 20\n",
        "#number of unique words in your dataset\n",
        "num_words = len(tokenizer.word_index)\n",
        "num_epochs = 5\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "# Embedding layer\n",
        "embedding = Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_seq_length)(inputs)\n",
        "# embedding = Flatten()(embedding)\n",
        "# Convolutional block 1\n",
        "conv_blocks_1 = []\n",
        "for filter_size in filter_sizes:\n",
        "    conv = Conv1D(filters=num_filters, kernel_size=filter_size, activation='relu')(embedding)\n",
        "    # conv = MaxPooling1D(pool_size=2)(conv)\n",
        "    # conv = Flatten()(conv)\n",
        "    conv_blocks_1.append(conv)\n",
        "concat1 = Concatenate(axis=1)(conv_blocks_1)\n",
        "\n",
        "maxpool_layer_1 = MaxPooling1D(pool_size=2)(concat1)\n",
        "\n",
        "# Convolutional block 2\n",
        "conv_blocks_2 = []\n",
        "for filter_size in filter_sizes:\n",
        "    conv = Conv1D(filters=num_filters, kernel_size=filter_size, activation='relu')(maxpool_layer_1)\n",
        "    # conv = MaxPooling1D(pool_size=2)(conv)\n",
        "    # conv = Flatten()(conv)\n",
        "    conv_blocks_2.append(conv)\n",
        "concat2 = Concatenate(axis=1)(conv_blocks_2)\n",
        "maxpool_layer_2 = MaxPooling1D(pool_size=2)(concat2)\n",
        "\n",
        "# Convolutional block 3\n",
        "conv3 = Conv1D(filters=num_filters, kernel_size=3, activation='relu')(maxpool_layer_2)\n",
        "\n",
        "# Flatten layer\n",
        "flatten = Flatten()(conv3)\n",
        "\n",
        "# Dropout layer\n",
        "dropout = Dropout(rate=0.5)(flatten)\n",
        "\n",
        "# Dense layer\n",
        "dense = Dense(units=32, activation='relu')(dropout)\n",
        "\n",
        "# Output layer\n",
        "outputs = Dense(units=num_classes, activation='softmax')(dense)\n",
        "#https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
        "# Compile the model\n",
        "print('-'*50)\n",
        "print(inputs.shape,outputs.shape )\n",
        "print('-'*50)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "#https://stackoverflow.com/questions/66554207/calculating-micro-f-1-score-in-keras\n",
        "# optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "# loss=tf.keras.losses.BinaryCrossentropy()\n",
        "# metrics=[tf.keras.metrics.BinaryAccuracy()\n",
        "checkpoint = ModelCheckpoint('weights_cnn_sentece.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
        "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "f1 = tfa.metrics.F1Score(num_classes=20, average='micro',threshold=0.5) \n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy',f1])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxaZjwRxbhlU",
        "outputId": "4cbcf245-756c-430c-f44f-1b2c7b42af52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "(None, 622) (None, 20)\n",
            "--------------------------------------------------\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 622)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 622, 300)     225600      ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_25 (Conv1D)             (None, 620, 16)      14416       ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_26 (Conv1D)             (None, 619, 16)      19216       ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 618, 16)      24016       ['embedding_5[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 1857, 16)     0           ['conv1d_25[0][0]',              \n",
            "                                                                  'conv1d_26[0][0]',              \n",
            "                                                                  'conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_8 (MaxPooling1D)  (None, 928, 16)     0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_28 (Conv1D)             (None, 926, 16)      784         ['max_pooling1d_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_29 (Conv1D)             (None, 925, 16)      1040        ['max_pooling1d_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 924, 16)      1296        ['max_pooling1d_8[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 2775, 16)     0           ['conv1d_28[0][0]',              \n",
            "                                                                  'conv1d_29[0][0]',              \n",
            "                                                                  'conv1d_30[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_9 (MaxPooling1D)  (None, 1387, 16)    0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 1385, 16)     784         ['max_pooling1d_9[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 22160)        0           ['conv1d_31[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 22160)        0           ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 32)           709152      ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 20)           660         ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 996,964\n",
            "Trainable params: 996,964\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n"
      ],
      "metadata": {
        "id": "Fa0zeuOIfhY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = np.reshape(X_train, (X_train.shape[0], ))\n",
        "# X_test = np.reshape(X_test, (X_test.shape[0],))"
      ],
      "metadata": {
        "id": "LBfcY15msKDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)\n",
        "print(X_train.shape)\n",
        "print(y_train)\n",
        "print(y_train.shape)\n",
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "KGnD-722Kqn4",
        "outputId": "9d2740ef-7bfd-49ac-c66f-70b5a8419df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    article writes article writes article writes s...\n",
            "2    article writes likely places there important s...\n",
            "6    writes writes world future l_clinton appoint c...\n",
            "4    writes article writes article writes however m...\n",
            "7    article writes article koppenhoefer cramm writ...\n",
            "1    article writes article wrence foard writes art...\n",
            "3    clinton email wondering congress alsogoing any...\n",
            "Name: combined_text, dtype: object\n",
            "(7,)\n",
            "0    0\n",
            "2    0\n",
            "6    0\n",
            "4    0\n",
            "7    0\n",
            "1    0\n",
            "3    0\n",
            "Name: label, dtype: int64\n",
            "(7,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'article writes article writes article writes simply propogranda phill really means because obviously using arguments designed convince secret stated explicitly posts political propagandist numerous occasions anyone posting group probably wrong group example numerous occasions stated quite clearly beleive certain factions lobby worst possible advocates their because prepared anything power provide platform because convince people better could people fixation lethal weapons dangerous derranged happen political position which nothave people advocating please point itout people accused inventing advocates purely purpose having trash political views would futile tactic because could never invent character dangerous quite seriously believe mentaly potential psychopath unfortunately local sherifs office informed unable untill attacks someone advantages drawbacks requiring proofon government before action reason believe weapons shouldbe available point trying current argument absolute sanctity constitution would answer arguing absolute sanctity fillibuster talking about constitution objected suggestion senatewas intended exercise power clearly given firstly current scene scene become special interests rather chase convenient caricatures about media polititians themselves rights cmapaigners zionists foreign lobbyists whatever voting power sugest really benefiting inevitable conclusion major corporations owned ultrawealthy benefited regan described welfare state point again reagan republican senate first coalition housecame about support incongress point everybody everywhere their corporations night leaving aconvenience store armful junkfood would bought withfood stamps spent stamps weekand government assitance money diverted programs addressing social needs poured weapons industry profits contracts lessee almanac total you s government budget outlays billiondollars trillion dollars increase ofapprox billion dollars billion dollars billion dollars increase billion dollars that leaves increase billion dollars unaccountedfor which includes retirement programs housing assitance unemployment benefits believe welfare billion dollars billion dollars ormore national defense started represented increaseof federal spent billion dollars onmedicare spent billion dollars increase billion dollars housingcredits subsidies billion health services research billiondollars billion dollars agriculture billion billion science billion billion resource conservation billion billion education billion billion veteran benefits billion billion trasnportation billion billion about things which seriously decreased under energy primarily under supply disaster relief between themrepresent billion dollars where diversion order rectify situation there constitutional revision stretch current government pushed bythe president create would expect begin toequalize pressure secondly revision account changed circumsatnces federal government assuming positive wantto continue little positive about constitution frustrate democratic process constitution designed frustrate voters could absolutely gettingwhat wanted happened putting thebrakes democratic process inherently thing every their ballot initiative nonsenseit worse peoplr welfare spending federal government sometimes perhaps people should betold pointed their local government attempting prevent through constitutional trickery leads constitution being brought disrepute phill would great favor repeating thatin methods always found bypass provisions government bypassing those provisions bypass others first ammendment eliminate violations eliminatingthe major reason right should excluded implication right equal right speech dangerous speech alone dangerous phill people ownership lethal weapons causes thousands murders dangerous conclusion reach first ammendment dangerous mistake phill clear pattern reduction homicide rates across several countries that llbe however slippery slope argument because right freedom speech chained privilege weaponry danger arises advocates pivilege allowed chain freedom speech their because freedom speech falls actions actions people genuinely interested freedom chaining anything freedom speech calling freedom thirdly importantly discover mechanism wherby engender intellectual debate opposed totemic debate consider grave threat civilisation ability reason about political debate anything other superficial level objection raise basing entirely assertion supremacy currency argument limited currency totem which based danger totems reinterpreted different different people phill master subtly changing subject based argument against democracy constitution i vetried explain referredto constitution point contain restrictionson senate appear believe meant butjust there constitution contain fillibuster rule i believe dismiss thatas venerating constitution because tenn education_o services_group still remember laughed dayyour pushed elevator shaft beginning think don tlove anymore weird_al  Propaganda   fillibuster utkvm1 utk edu dscomsa desy dscomsa desy utkvm1 utk edu utkvm1 utk edu dscomsa desy dscomsa desy utkvm1 utk edu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded.shape, y_train_ohe.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJsDpkWVxtnI",
        "outputId": "bd786e7c-8442-4308-a9e8-aeacef77a4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7, 622), (7, 20))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://stackoverflow.com/questions/73277459/warningtensorflowmodel-was-constructed-with-shape-none-66-200-3\n",
        "# history = model.fit(train_data, train_labels, validation_data=(test_data, test_labels), epochs=num_epochs, callbacks=[early_stopping])\n",
        "# model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(x_val, y_val))\n",
        "print(\"Traning Model...\")\n",
        "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, verbose=1,epochs=num_epochs, callbacks=[early_stopping])\n",
        "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=1,epochs=num_epochs, callbacks=[early_stopping])\n",
        "# history = model.fit(X_train_padded, y_train_ohe, validation_data=(X_test_padded, y_test_ohe), verbose=1,epochs=num_epochs, callbacks=[early_stopping])\n",
        "history = model.fit(X_train_padded, y_train_ohe, validation_data=(X_test_padded, y_test_ohe), epochs=num_epochs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AaNFNMrgf11y",
        "outputId": "282868cc-deb3-4913-eef6-25f09602b348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traning Model...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-571b2f8394fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=1,epochs=num_epochs, callbacks=[early_stopping])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# history = model.fit(X_train_padded, y_train_ohe, validation_data=(X_test_padded, y_test_ohe), verbose=1,epochs=num_epochs, callbacks=[early_stopping])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ohe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_ohe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_4/embedding_5/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-58-571b2f8394fc>\", line 8, in <module>\n      history = model.fit(X_train_padded, y_train_ohe, validation_data=(X_test_padded, y_test_ohe), epochs=num_epochs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/core/embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_4/embedding_5/embedding_lookup'\nindices[1,20] = 752 is not in [0, 752)\n\t [[{{node model_4/embedding_5/embedding_lookup}}]] [Op:__inference_train_function_6339]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step-14: To save a plot of the model with shapes, we can use the plot_model function from Keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True)\n",
        "\n",
        "#This will save a PNG image of the model with shapes in the current directory. We can then include this image in a markdown cell using the following code:\n",
        "![Model Architecture](model.png)"
      ],
      "metadata": {
        "id": "XpXy7gDuney8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0mwdtcvYv1X"
      },
      "source": [
        "### Model-1: Using 1D convolutions with word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXPPsovJ3ePk"
      },
      "source": [
        "<pre>\n",
        "<b>Encoding of the Text </b> --> For a given text data create a Matrix with Embedding layer as shown Below. \n",
        "In the example we have considered d = 5, but in this assignment we will get d = dimension of Word vectors we are using.\n",
        " i.e if we have maximum of 350 words in a sentence and embedding of 300 dim word vector, \n",
        " we result in 350*300 dimensional matrix for each sentance as output after embedding layer\n",
        "<img src='https://i.imgur.com/kiVQuk1.png'>\n",
        "Ref: https://i.imgur.com/kiVQuk1.png\n",
        "\n",
        "<b>Reference:</b>\n",
        "<a href='https://stackoverflow.com/a/43399308/4084039'>https://stackoverflow.com/a/43399308/4084039</a>\n",
        "<a href='https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/'>https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/</a>\n",
        "\n",
        "<b><a href='https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work'>How EMBEDDING LAYER WORKS </a></b>\n",
        "\n",
        "</pre>\n",
        "\n",
        "### Go through this blog, if you have any doubt on using predefined Embedding values in Embedding layer - https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGVQKge3Yv1e"
      },
      "source": [
        "<img src='https://i.imgur.com/fv1GvFJ.png'>\n",
        "ref: 'https://i.imgur.com/fv1GvFJ.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC6SBG5AYv1f"
      },
      "source": [
        "<pre>\n",
        "1. all are Conv1D layers with any number of filter and filter sizes, there is no restriction on this.\n",
        "\n",
        "2. use concatenate layer is to concatenate all the filters/channels. \n",
        "\n",
        "3. You can use any pool size and stride for maxpooling layer.\n",
        "\n",
        "4. Don't use more than 16 filters in one Conv layer becuase it will increase the no of params. \n",
        "( Only recommendation if you have less computing power )\n",
        "\n",
        "5. You can use any number of layers after the Flatten Layer.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cg4L1V4Yv1d"
      },
      "source": [
        "### Model-2 : Using 1D convolutions with character embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Djg4YVA3oQx"
      },
      "source": [
        "<pre>\n",
        "<pre><img src=\"https://i.ytimg.com/vi/CNY8VjJt-iQ/maxresdefault.jpg\" width=\"70%\">\n",
        "Here are the some papers based on Char-CNN\n",
        " 1. Xiang Zhang, Junbo Zhao, Yann LeCun. <a href=\"http://arxiv.org/abs/1509.01626\">Character-level Convolutional Networks for Text Classification</a>.NIPS 2015\n",
        " 2. Yoon Kim, Yacine Jernite, David Sontag, Alexander M. Rush. <a href=\"https://arxiv.org/abs/1508.06615\">Character-Aware Neural Language Models</a>. AAAI 2016\n",
        " 3. Shaojie Bai, J. Zico Kolter, Vladlen Koltun. <a href=\"https://arxiv.org/pdf/1803.01271.pdf\">An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling</a>\n",
        " 4. Use the pratrained char embeddings <a href='https://github.com/minimaxir/char-embeddings/blob/master/glove.840B.300d-char.txt'>https://github.com/minimaxir/char-embeddings/blob/master/glove.840B.300d-char.txt</a>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXvKSEIeSvN5"
      },
      "source": [
        "<img src='https://i.imgur.com/EuuoJtr.png'>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_dir_glove_vec = '/content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata'\n",
        "# /content/drive/MyDrive/Colab Notebooks/AAIC_Assignments/solving/21_Transfer Learning_CNN_with_textdata/glove.6B.300d.txt\n",
        "embeddings_dict = {}\n",
        "with open(os.path.join(path_dir_glove_vec, 'glove.6B.300d.txt'), 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in tqdm(lines,desc=\"Processing lines\"):\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_dict[word] = coefs"
      ],
      "metadata": {
        "id": "qAhe5p_xw9P1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ba0ee13f3e2e48e58ae356e4bb49e78b",
            "7124a3d344794c078be13d2b51d12c63",
            "45cfe710b3574cc3b70e4d4943a12c6a",
            "27fd614f0cd04e1380ee45937f41aec4",
            "48a6e779051a43e2aef0402ca08c5324",
            "1e0add167af04ec099d530d921a4705b",
            "9e4e590039064febb85011f1208e5062",
            "3f872c56fab94f73a1f3b9bb171e81e0",
            "bd3d7486adc54c849da4fdaf68d735e2",
            "7081df0ea46c4be4bc38a1b832289c1c",
            "80c9dd012dde4a138fb8a5c716d7feef"
          ]
        },
        "outputId": "837894f2-c91f-4166-9c4e-d93d552322ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing lines:   0%|          | 0/400000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba0ee13f3e2e48e58ae356e4bb49e78b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_chars = set()\n",
        "for text in df['text']:\n",
        "    all_chars.update(set(text))\n",
        "char_to_index = {char: i+1 for i, char in enumerate(sorted(all_chars))}\n"
      ],
      "metadata": {
        "id": "Nw__IoC2w-NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300 # change this as per your requirements\n",
        "num_chars = len(char_to_index)\n",
        "embedding_matrix = np.zeros((num_chars+1, embedding_dim))\n",
        "for char, i in char_to_index.items():\n",
        "    embedding_vector = embeddings_dict.get(char)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "5n5pCQtCw-ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = maxlen    # 1000 # change this as per your requirements\n",
        "X = df['combined_text'].apply(lambda x: [char_to_index.get(char, 0) for char in x])\n",
        "X = pad_sequences(X, maxlen=max_len, padding='post', truncating='post')\n"
      ],
      "metadata": {
        "id": "PIQ3sCD-w-je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(num_chars+1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)\n"
      ],
      "metadata": {
        "id": "hy2u7fOGykwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dropout, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "\n",
        "# Define the model architecture\n",
        "input_layer = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(input_dim=num_chars, output_dim=embedding_dim, input_length=maxlen)(input_layer)\n",
        "conv1d_1 = Conv1D(filters=32, kernel_size=3, activation='relu')(embedding_layer)\n",
        "conv1d_2 = Conv1D(filters=16, kernel_size=5, activation='relu')(conv1d_1)\n",
        "maxpooling_1 = MaxPooling1D(pool_size=2)(conv1d_2)\n",
        "conv1d_3 = Conv1D(filters=16, kernel_size=3, activation='relu')(maxpooling_1)\n",
        "conv1d_4 = Conv1D(filters=8, kernel_size=5, activation='relu')(conv1d_3)\n",
        "maxpooling_2 = MaxPooling1D(pool_size=2)(conv1d_4)\n",
        "flatten = Flatten()(maxpooling_2)\n",
        "dropout = Dropout(0.2)(flatten)\n",
        "dense = Dense(32, activation='relu')(dropout)\n",
        "output_layer = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "# f1 = F1Score(num_classes=num_classes, name='f1_score', average='micro')\n",
        "f1 = tfa.metrics.F1Score(num_classes=20, average='micro',threshold=0.5)\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', f1])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Plot the model\n",
        "plot_model(model, to_file='1Dconv_char_embedding.png', show_shapes=True)\n",
        "\n",
        "# Define the callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lWISuMlEAMwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d728f9e5-601d-41e6-9da6-5471c3a776db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 622)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 622, 300)          27300     \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 620, 32)           28832     \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 616, 16)           2576      \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 308, 16)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 306, 16)           784       \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 302, 8)            648       \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 151, 8)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1208)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1208)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                38688     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 98,861\n",
            "Trainable params: 98,861\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=1, verbose=1, epochs=num_epochs, callbacks=[early_stopping])  #batch_size = ?\n",
        " \n",
        "# Evaluate the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "aLCXBAuBy2QV",
        "outputId": "aa5e87ab-f275-4c16-f29b-49753ebfe07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 622) for input KerasTensor(type_spec=TensorSpec(shape=(None, 622), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (1, 1).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4c8f06dbb8ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#batch_size = ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'conv1d_7' (type Conv1D).\n    \n    Negative dimension size caused by subtracting 3 from 1 for '{{node model_1/conv1d_7/Conv1D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](model_1/conv1d_7/Conv1D/ExpandDims, model_1/conv1d_7/Conv1D/ExpandDims_1)' with input shapes: [1,1,1,300], [1,3,300,32].\n    \n    Call arguments received by layer 'conv1d_7' (type Conv1D):\n      • inputs=tf.Tensor(shape=(1, 1, 300), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J-3FZIGKyo5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/au1206/Convolutional-Neural-Networks-for-Sentence-Classification/blob/master/cnn_sentence_classification.ipynb"
      ],
      "metadata": {
        "id": "FBumBa4cIZhQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}